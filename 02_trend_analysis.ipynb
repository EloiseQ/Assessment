{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02: Lead Quality Trend Analysis\n",
        "\n",
        "## Question 1: Is lead quality improving/declining over time? Is it statistically significant?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_pickle('df_cleaned.pkl')\n",
        "print(f\"Data shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1 Aggregate by Day and Week, Plot Trends"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "daily_stats = df.groupby('date').agg({\n",
        "    'is_good': ['sum', 'count'],\n",
        "    'is_closed': 'sum',\n",
        "    'is_bad': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "daily_stats.columns = ['date', 'good_count', 'total_count', 'closed_count', 'bad_count']\n",
        "daily_stats['GoodQualityRate'] = daily_stats['good_count'] / daily_stats['total_count']\n",
        "daily_stats['CloseRate'] = daily_stats['closed_count'] / daily_stats['total_count']\n",
        "daily_stats['BadRate'] = daily_stats['bad_count'] / daily_stats['total_count']\n",
        "\n",
        "daily_stats['GoodQualityRate_7d'] = daily_stats['GoodQualityRate'].rolling(window=7, min_periods=1).mean()\n",
        "daily_stats['CloseRate_7d'] = daily_stats['CloseRate'].rolling(window=7, min_periods=1).mean()\n",
        "daily_stats['BadRate_7d'] = daily_stats['BadRate'].rolling(window=7, min_periods=1).mean()\n",
        "\n",
        "from scipy.stats import binom\n",
        "def calc_ci(n, p, alpha=0.05):\n",
        "    if n == 0:\n",
        "        return (0, 0)\n",
        "    se = np.sqrt(p * (1 - p) / n)\n",
        "    z = stats.norm.ppf(1 - alpha/2)\n",
        "    ci_lower = max(0, p - z * se)\n",
        "    ci_upper = min(1, p + z * se)\n",
        "    return (ci_lower, ci_upper)\n",
        "\n",
        "daily_stats['GoodQualityRate_ci_lower'] = daily_stats.apply(\n",
        "    lambda row: calc_ci(row['total_count'], row['GoodQualityRate'])[0], axis=1\n",
        ")\n",
        "daily_stats['GoodQualityRate_ci_upper'] = daily_stats.apply(\n",
        "    lambda row: calc_ci(row['total_count'], row['GoodQualityRate'])[1], axis=1\n",
        ")\n",
        "\n",
        "print(\"Daily statistics (first 10 days):\")\n",
        "print(daily_stats.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weekly_stats = df.groupby('week').agg({\n",
        "    'is_good': ['sum', 'count'],\n",
        "    'is_closed': 'sum',\n",
        "    'is_bad': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "weekly_stats.columns = ['week', 'good_count', 'total_count', 'closed_count', 'bad_count']\n",
        "weekly_stats['GoodQualityRate'] = weekly_stats['good_count'] / weekly_stats['total_count']\n",
        "weekly_stats['CloseRate'] = weekly_stats['closed_count'] / weekly_stats['total_count']\n",
        "weekly_stats['BadRate'] = weekly_stats['bad_count'] / weekly_stats['total_count']\n",
        "\n",
        "print(\"Weekly statistics:\")\n",
        "print(weekly_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(14, 12))\n",
        "\n",
        "ax1 = axes[0]\n",
        "ax1.plot(daily_stats['date'], daily_stats['GoodQualityRate'], 'o-', alpha=0.6, label='Daily Rate', markersize=4)\n",
        "ax1.plot(daily_stats['date'], daily_stats['GoodQualityRate_7d'], '-', linewidth=2, label='7-Day Rolling Mean', color='red')\n",
        "ax1.fill_between(daily_stats['date'], daily_stats['GoodQualityRate_ci_lower'], \n",
        "                 daily_stats['GoodQualityRate_ci_upper'], alpha=0.2, label='95% CI')\n",
        "ax1.set_title('GoodQualityRate Trend (Daily)', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Rate', fontsize=12)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2 = axes[1]\n",
        "ax2.plot(daily_stats['date'], daily_stats['CloseRate'], 'o-', alpha=0.6, label='Daily Rate', markersize=4)\n",
        "ax2.plot(daily_stats['date'], daily_stats['CloseRate_7d'], '-', linewidth=2, label='7-Day Rolling Mean', color='red')\n",
        "ax2.set_title('CloseRate Trend (Daily)', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Rate', fontsize=12)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "ax3 = axes[2]\n",
        "ax3.plot(daily_stats['date'], daily_stats['BadRate'], 'o-', alpha=0.6, label='Daily Rate', markersize=4)\n",
        "ax3.plot(daily_stats['date'], daily_stats['BadRate_7d'], '-', linewidth=2, label='7-Day Rolling Mean', color='red')\n",
        "ax3.set_title('BadRate Trend (Daily)', fontsize=14, fontweight='bold')\n",
        "ax3.set_ylabel('Rate', fontsize=12)\n",
        "ax3.set_xlabel('Date', fontsize=12)\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('trend_daily.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 Statistical Significance Tests\n",
        "\n",
        "### Method 1: Two-Segment Comparison (First Half vs Second Half)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sorted = df.sort_values('date').reset_index(drop=True)\n",
        "mid_point = len(df_sorted) // 2\n",
        "\n",
        "first_half = df_sorted.iloc[:mid_point]\n",
        "second_half = df_sorted.iloc[mid_point:]\n",
        "\n",
        "rate_first = first_half['is_good'].mean()\n",
        "rate_second = second_half['is_good'].mean()\n",
        "n_first = len(first_half)\n",
        "n_second = len(second_half)\n",
        "count_first = first_half['is_good'].sum()\n",
        "count_second = second_half['is_good'].sum()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Two-Segment Comparison Analysis (First Half vs Second Half)\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nFirst Half:\")\n",
        "print(f\"  Sample size: {n_first}\")\n",
        "print(f\"  GoodQualityRate: {rate_first:.4f} ({rate_first*100:.2f}%)\")\n",
        "print(f\"  Good quality count: {count_first}\")\n",
        "\n",
        "print(f\"\\nSecond Half:\")\n",
        "print(f\"  Sample size: {n_second}\")\n",
        "print(f\"  GoodQualityRate: {rate_second:.4f} ({rate_second*100:.2f}%)\")\n",
        "print(f\"  Good quality count: {count_second}\")\n",
        "\n",
        "print(f\"\\nDifference: {rate_second - rate_first:.4f} ({((rate_second - rate_first)/rate_first*100):.2f}%)\")\n",
        "\n",
        "counts = np.array([count_first, count_second])\n",
        "nobs = np.array([n_first, n_second])\n",
        "z_stat, p_value = proportions_ztest(counts, nobs)\n",
        "\n",
        "print(f\"\\nTwo-Proportion Z-Test:\")\n",
        "print(f\"  z-statistic: {z_stat:.4f}\")\n",
        "print(f\"  p-value: {p_value:.4f}\")\n",
        "print(f\"  Significance: {'Significant' if p_value < 0.05 else 'Not significant'} (α=0.05)\")\n",
        "\n",
        "from scipy.stats import fisher_exact\n",
        "contingency_table = [[count_first, n_first - count_first],\n",
        "                     [count_second, n_second - count_second]]\n",
        "oddsratio, p_fisher = fisher_exact(contingency_table)\n",
        "print(f\"\\nFisher Exact Test:\")\n",
        "print(f\"  Odds ratio: {oddsratio:.4f}\")\n",
        "print(f\"  p-value: {p_fisher:.4f}\")\n",
        "print(f\"  Significance: {'Significant' if p_fisher < 0.05 else 'Not significant'} (α=0.05)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 2: Trend Regression (Logistic Regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from statsmodels.api import Logit\n",
        "\n",
        "X = df_sorted[['day_index']].values\n",
        "y = df_sorted['is_good'].values\n",
        "\n",
        "logit_model = Logit(y, X)\n",
        "logit_result = logit_model.fit(disp=0)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Trend Regression Analysis (Logistic Regression)\")\n",
        "print(\"=\" * 60)\n",
        "print(logit_result.summary())\n",
        "\n",
        "coef = logit_result.params[0]\n",
        "p_value_coef = logit_result.pvalues[0]\n",
        "\n",
        "print(f\"\\nTime coefficient: {coef:.6f}\")\n",
        "print(f\"p-value: {p_value_coef:.4f}\")\n",
        "print(f\"Significance: {'Significant' if p_value_coef < 0.05 else 'Not significant'} (α=0.05)\")\n",
        "print(f\"Trend direction: {'Increasing' if coef > 0 else 'Decreasing'}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 3: Trend Test Only in Score Coverage Period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'address_score_bin' in df.columns:\n",
        "    df_with_scores = df[df['address_score_bin'] != 'missing'].copy()\n",
        "    \n",
        "    if len(df_with_scores) > 100:\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Trend Analysis in Score Coverage Period\")\n",
        "        print(\"=\" * 60)\n",
        "        print(f\"Score coverage period sample size: {len(df_with_scores)}\")\n",
        "        print(f\"Score coverage period GoodQualityRate: {df_with_scores['is_good'].mean():.4f} ({df_with_scores['is_good'].mean()*100:.2f}%)\")\n",
        "        \n",
        "        df_with_scores_sorted = df_with_scores.sort_values('date').reset_index(drop=True)\n",
        "        df_with_scores_sorted['day_index_score'] = (df_with_scores_sorted['date'] - df_with_scores_sorted['date'].min()).dt.days\n",
        "        \n",
        "        X_score = df_with_scores_sorted[['day_index_score']].values\n",
        "        y_score = df_with_scores_sorted['is_good'].values\n",
        "        \n",
        "        logit_model_score = Logit(y_score, X_score)\n",
        "        logit_result_score = logit_model_score.fit(disp=0)\n",
        "        \n",
        "        print(f\"\\nTime coefficient: {logit_result_score.params[0]:.6f}\")\n",
        "        print(f\"p-value: {logit_result_score.pvalues[0]:.4f}\")\n",
        "        print(f\"Significance: {'Significant' if logit_result_score.pvalues[0] < 0.05 else 'Not significant'} (α=0.05)\")\n",
        "        print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3 Trend Analysis Conclusion Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "overall_rate = df['is_good'].mean()\n",
        "first_half_rate = first_half['is_good'].mean()\n",
        "second_half_rate = second_half['is_good'].mean()\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Trend Analysis Conclusion Summary\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nOverall GoodQualityRate: {overall_rate:.4f} ({overall_rate*100:.2f}%)\")\n",
        "print(f\"First Half GoodQualityRate: {first_half_rate:.4f} ({first_half_rate*100:.2f}%)\")\n",
        "print(f\"Second Half GoodQualityRate: {second_half_rate:.4f} ({second_half_rate*100:.2f}%)\")\n",
        "print(f\"\\nChange direction: {'Improving' if second_half_rate > first_half_rate else 'Declining' if second_half_rate < first_half_rate else 'No significant change'}\")\n",
        "print(f\"Change magnitude: {abs(second_half_rate - first_half_rate):.4f} ({abs((second_half_rate - first_half_rate)/first_half_rate*100):.2f}%)\")\n",
        "print(f\"\\nStatistical significance (z-test): p={p_value:.4f}, {'Significant' if p_value < 0.05 else 'Not significant'}\")\n",
        "print(f\"Statistical significance (logistic): p={p_value_coef:.4f}, {'Significant' if p_value_coef < 0.05 else 'Not significant'}\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
