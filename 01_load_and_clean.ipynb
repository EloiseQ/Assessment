{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01: Data Loading and Cleaning\n",
        "\n",
        "## Objectives\n",
        "- Load Excel data\n",
        "- Basic quality checks\n",
        "- Define Lead Quality primary metrics\n",
        "- Derive core fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Load Excel Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'Analyst_case_study_dataset_1_(1) (1).xls'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "print(f\"Data shape: {df.shape}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df.columns.tolist())\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Basic Quality Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Total rows: {len(df)}\")\n",
        "print(f\"Expected: ~3000\")\n",
        "print(f\"Difference: {len(df) - 3000}\")\n",
        "\n",
        "vendor_id_col = df.columns[0]\n",
        "print(f\"\\nVendorLeadID column: {vendor_id_col}\")\n",
        "print(f\"Unique values: {df[vendor_id_col].nunique()}\")\n",
        "print(f\"Total rows: {len(df)}\")\n",
        "\n",
        "if df[vendor_id_col].nunique() < len(df):\n",
        "    duplicates = df[df[vendor_id_col].duplicated(keep=False)]\n",
        "    print(f\"\\nFound duplicates: {len(duplicates)} rows\")\n",
        "    print(duplicates.head())\n",
        "    df = df.drop_duplicates(subset=[vendor_id_col], keep='first')\n",
        "    print(f\"\\nRows after deduplication: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "call_status_col = df.columns[4] if len(df.columns) > 4 else df.columns[-1]\n",
        "print(f\"CallStatus column: {call_status_col}\")\n",
        "\n",
        "print(f\"\\nCallStatus unique values:\")\n",
        "print(df[call_status_col].value_counts())\n",
        "print(f\"\\nNull count: {df[call_status_col].isna().sum()}\")\n",
        "print(f\"\\nAll unique values:\")\n",
        "print(df[call_status_col].unique())\n",
        "\n",
        "date_col = df.columns[0]\n",
        "print(f\"\\nDate column: {date_col}\")\n",
        "\n",
        "df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "print(f\"\\nNulls after datetime conversion: {df[date_col].isna().sum()}\")\n",
        "print(f\"Date range: {df[date_col].min()} to {df[date_col].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "score_cols = [col for col in df.columns if 'score' in col.lower() or 'Score' in col]\n",
        "print(f\"Found Score columns: {score_cols}\")\n",
        "\n",
        "for col in score_cols:\n",
        "    missing_pct = df[col].isna().sum() / len(df) * 100\n",
        "    print(f\"\\n{col}:\")\n",
        "    print(f\"  Missing count: {df[col].isna().sum()}\")\n",
        "    print(f\"  Missing percentage: {missing_pct:.2f}%\")\n",
        "    if df[col].notna().sum() > 0:\n",
        "        print(f\"  Non-missing value distribution:\")\n",
        "        print(df[col].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Map CallStatus to 4 Groups + Binary Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def map_call_status(status):\n",
        "    if pd.isna(status):\n",
        "        return 'unknown'\n",
        "    \n",
        "    status_str = str(status).strip().lower()\n",
        "    \n",
        "    if 'closed' in status_str:\n",
        "        return 'closed'\n",
        "    \n",
        "    if any(x in status_str for x in ['ep sent', 'ep received', 'ep confirmed']):\n",
        "        return 'good'\n",
        "    \n",
        "    if any(x in status_str for x in ['unable to contact', 'invalid profile', \"doesn't qualify\", \"doesnt qualify\"]):\n",
        "        return 'bad'\n",
        "    \n",
        "    return 'unknown'\n",
        "\n",
        "df['status_group'] = df[call_status_col].apply(map_call_status)\n",
        "\n",
        "df['is_good'] = df['status_group'].isin(['closed', 'good']).astype(int)\n",
        "df['is_closed'] = (df['status_group'] == 'closed').astype(int)\n",
        "df['is_bad'] = (df['status_group'] == 'bad').astype(int)\n",
        "\n",
        "print(\"Status Group distribution:\")\n",
        "print(df['status_group'].value_counts())\n",
        "print(\"\\nBinary label statistics:\")\n",
        "print(f\"is_good=1: {df['is_good'].sum()} ({df['is_good'].mean()*100:.2f}%)\")\n",
        "print(f\"is_closed=1: {df['is_closed'].sum()} ({df['is_closed'].mean()*100:.2f}%)\")\n",
        "print(f\"is_bad=1: {df['is_bad'].sum()} ({df['is_bad'].mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.1 Define Lead Quality Primary Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_leads = len(df)\n",
        "good_quality_count = df['is_good'].sum()\n",
        "closed_count = df['is_closed'].sum()\n",
        "bad_count = df['is_bad'].sum()\n",
        "\n",
        "GoodQualityRate = good_quality_count / all_leads\n",
        "CloseRate = closed_count / all_leads\n",
        "BadRate = bad_count / all_leads\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"LEAD QUALITY PRIMARY METRICS DEFINITION\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal Leads: {all_leads}\")\n",
        "print(f\"\\n1. GoodQualityRate (Primary): {GoodQualityRate:.4f} ({GoodQualityRate*100:.2f}%)\")\n",
        "print(f\"   Definition: (Closed + EP Sent + EP Received + EP Confirmed) / All\")\n",
        "print(f\"   Numerator: {good_quality_count}\")\n",
        "print(f\"\\n2. CloseRate: {CloseRate:.4f} ({CloseRate*100:.2f}%)\")\n",
        "print(f\"   Definition: Closed / All\")\n",
        "print(f\"   Numerator: {closed_count}\")\n",
        "print(f\"\\n3. BadRate: {BadRate:.4f} ({BadRate*100:.2f}%)\")\n",
        "print(f\"   Definition: (Unable to Contact + Invalid Profile + Doesn't Qualify) / All\")\n",
        "print(f\"   Numerator: {bad_count}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Derive Time Fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['date'] = df[date_col].dt.date\n",
        "df['week'] = df[date_col].dt.to_period('W')\n",
        "df['dow'] = df[date_col].dt.day_name()\n",
        "df['day_index'] = (df[date_col] - df[date_col].min()).dt.days\n",
        "\n",
        "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
        "print(f\"Number of weeks: {df['week'].nunique()}\")\n",
        "print(f\"\\nWeekly statistics:\")\n",
        "print(df.groupby('week').size().head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Cleaned Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_pickle('df_cleaned.pkl')\n",
        "print(\"Data saved to df_cleaned.pkl\")\n",
        "print(f\"\\nFinal data shape: {df.shape}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Engineering\n",
        "\n",
        "### 4.1 Parse WidgetName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "widget_col = None\n",
        "for col in df.columns:\n",
        "    if 'widget' in col.lower() or 'WidgetName' in col:\n",
        "        widget_col = col\n",
        "        break\n",
        "\n",
        "if widget_col:\n",
        "    print(f\"Found WidgetName column: {widget_col}\")\n",
        "    print(f\"\\nWidgetName sample values:\")\n",
        "    print(df[widget_col].head(10).tolist())\n",
        "    \n",
        "    def parse_widget_name(name):\n",
        "        if pd.isna(name):\n",
        "            return {'ad_size': None, 'dc_pages': None, 'design': None, 'bg_color': None}\n",
        "        \n",
        "        name_str = str(name).strip()\n",
        "        parts = name_str.split('_')\n",
        "        \n",
        "        result = {\n",
        "            'ad_size': None,\n",
        "            'dc_pages': None,\n",
        "            'design': None,\n",
        "            'bg_color': None\n",
        "        }\n",
        "        \n",
        "        if len(parts) >= 1:\n",
        "            size = parts[0]\n",
        "            if size in ['300250', '302252']:\n",
        "                result['ad_size'] = '302252'\n",
        "            else:\n",
        "                result['ad_size'] = size\n",
        "        \n",
        "        if len(parts) >= 2:\n",
        "            dc = parts[1].upper()\n",
        "            if '1DC' in dc or '1' in dc:\n",
        "                result['dc_pages'] = '1DC'\n",
        "            elif '2DC' in dc or '2' in dc:\n",
        "                result['dc_pages'] = '2DC'\n",
        "        \n",
        "        if len(parts) >= 3:\n",
        "            result['design'] = parts[2]\n",
        "        \n",
        "        if len(parts) >= 4:\n",
        "            result['bg_color'] = parts[3]\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    widget_parsed = df[widget_col].apply(parse_widget_name)\n",
        "    df['ad_size'] = widget_parsed.apply(lambda x: x['ad_size'])\n",
        "    df['dc_pages'] = widget_parsed.apply(lambda x: x['dc_pages'])\n",
        "    df['design'] = widget_parsed.apply(lambda x: x['design'])\n",
        "    df['bg_color'] = widget_parsed.apply(lambda x: x['bg_color'])\n",
        "    \n",
        "    print(\"\\nParsing results:\")\n",
        "    print(f\"ad_size distribution:\")\n",
        "    print(df['ad_size'].value_counts())\n",
        "    print(f\"\\ndc_pages distribution:\")\n",
        "    print(df['dc_pages'].value_counts())\n",
        "else:\n",
        "    print(\"WidgetName column not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Call Center vs Online Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "publisher_campaign_col = df.columns[7] if len(df.columns) > 7 else None\n",
        "if publisher_campaign_col:\n",
        "    print(f\"PublisherCampaignName column: {publisher_campaign_col}\")\n",
        "    df['is_call_center'] = df[publisher_campaign_col].astype(str).str.contains('Call Center', case=False, na=False)\n",
        "    print(f\"\\nCall Center distribution:\")\n",
        "    print(df['is_call_center'].value_counts())\n",
        "    \n",
        "    publisher_zone_col = df.columns[6] if len(df.columns) > 6 else None\n",
        "    if publisher_zone_col:\n",
        "        df['publisher_zone'] = df[publisher_zone_col]\n",
        "        print(f\"\\nPublisherZoneName distribution:\")\n",
        "        print(df['publisher_zone'].value_counts().head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Bin AddressScore and PhoneScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bin_score(score_series, name):\n",
        "    result = score_series.copy().astype(str)\n",
        "    result[score_series.isna()] = 'missing'\n",
        "    result[(score_series >= 1) & (score_series <= 2)] = '1-2'\n",
        "    result[(score_series >= 3) & (score_series <= 4)] = '3-4'\n",
        "    result[score_series == 5] = '5'\n",
        "    return result\n",
        "\n",
        "address_score_col = None\n",
        "phone_score_col = None\n",
        "\n",
        "for col in df.columns:\n",
        "    if 'address' in col.lower() and 'score' in col.lower():\n",
        "        address_score_col = col\n",
        "    if 'phone' in col.lower() and 'score' in col.lower():\n",
        "        phone_score_col = col\n",
        "\n",
        "if address_score_col:\n",
        "    df['address_score_bin'] = bin_score(df[address_score_col], 'AddressScore')\n",
        "    print(f\"AddressScore bin distribution:\")\n",
        "    print(df['address_score_bin'].value_counts())\n",
        "\n",
        "if phone_score_col:\n",
        "    df['phone_score_bin'] = bin_score(df[phone_score_col], 'PhoneScore')\n",
        "    print(f\"\\nPhoneScore bin distribution:\")\n",
        "    print(df['phone_score_bin'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Branded vs Generic Flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "advertiser_campaign_col = None\n",
        "for col in df.columns:\n",
        "    if 'advertiser' in col.lower() and 'campaign' in col.lower():\n",
        "        advertiser_campaign_col = col\n",
        "        break\n",
        "\n",
        "if advertiser_campaign_col:\n",
        "    print(f\"AdvertiserCampaignName column: {advertiser_campaign_col}\")\n",
        "    df['is_branded'] = df[advertiser_campaign_col].astype(str).str.contains(\n",
        "        'branded|creditsolutions', case=False, na=False\n",
        "    )\n",
        "    print(f\"\\nBranded distribution:\")\n",
        "    print(df['is_branded'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Other Features (Debt, State, Traffic Type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "debt_col = None\n",
        "for col in df.columns:\n",
        "    if 'debt' in col.lower():\n",
        "        debt_col = col\n",
        "        break\n",
        "\n",
        "if debt_col:\n",
        "    print(f\"Debt column: {debt_col}\")\n",
        "    df['debt_bin'] = pd.qcut(df[debt_col], q=3, labels=['Low', 'Medium', 'High'], duplicates='drop')\n",
        "    print(f\"\\nDebt bin distribution:\")\n",
        "    print(df['debt_bin'].value_counts())\n",
        "\n",
        "state_col = None\n",
        "for col in df.columns:\n",
        "    if 'state' in col.lower() and col.lower() != 'address':\n",
        "        state_col = col\n",
        "        break\n",
        "\n",
        "if state_col:\n",
        "    df['state'] = df[state_col]\n",
        "    print(f\"\\nState distribution (Top 10):\")\n",
        "    print(df['state'].value_counts().head(10))\n",
        "\n",
        "campaign_col = None\n",
        "for col in df.columns:\n",
        "    if 'campaign' in col.lower() and 'publisher' not in col.lower() and 'advertiser' not in col.lower():\n",
        "        campaign_col = col\n",
        "        break\n",
        "\n",
        "if campaign_col:\n",
        "    df['traffic_type'] = df[campaign_col].astype(str).str.contains('content', case=False, na=False)\n",
        "    df['traffic_type'] = df['traffic_type'].map({True: 'content', False: 'search'})\n",
        "    print(f\"\\nTraffic Type distribution:\")\n",
        "    print(df['traffic_type'].value_counts())"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
