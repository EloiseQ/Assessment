{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03: Driver Analysis and Segmentation\n",
        "\n",
        "## Question 2: Which segments have higher/lower quality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from statsmodels.stats.proportion import proportions_ztest\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df = pd.read_pickle('df_cleaned.pkl')\n",
        "baseline_rate = df['is_good'].mean()\n",
        "print(f\"Baseline GoodQualityRate: {baseline_rate:.4f} ({baseline_rate*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Univariate Segmentation Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def segment_analysis(df, segment_col, baseline_rate):\n",
        "    results = []\n",
        "    \n",
        "    for segment in df[segment_col].unique():\n",
        "        if pd.isna(segment):\n",
        "            segment_df = df[df[segment_col].isna()]\n",
        "            segment_name = 'missing'\n",
        "        else:\n",
        "            segment_df = df[df[segment_col] == segment]\n",
        "            segment_name = str(segment)\n",
        "        \n",
        "        if len(segment_df) == 0:\n",
        "            continue\n",
        "        \n",
        "        n = len(segment_df)\n",
        "        good_count = segment_df['is_good'].sum()\n",
        "        closed_count = segment_df['is_closed'].sum()\n",
        "        bad_count = segment_df['is_bad'].sum()\n",
        "        \n",
        "        good_rate = good_count / n\n",
        "        close_rate = closed_count / n\n",
        "        bad_rate = bad_count / n\n",
        "        \n",
        "        lift = good_rate / baseline_rate if baseline_rate > 0 else 0\n",
        "        \n",
        "        se = np.sqrt(good_rate * (1 - good_rate) / n)\n",
        "        z = stats.norm.ppf(0.975)\n",
        "        ci_lower = max(0, good_rate - z * se)\n",
        "        ci_upper = min(1, good_rate + z * se)\n",
        "        \n",
        "        counts = np.array([good_count, baseline_rate * len(df)])\n",
        "        nobs = np.array([n, len(df)])\n",
        "        z_stat, p_value = proportions_ztest(counts, nobs)\n",
        "        \n",
        "        results.append({\n",
        "            'segment': segment_name,\n",
        "            'leads': n,\n",
        "            'GoodQualityRate': good_rate,\n",
        "            'CloseRate': close_rate,\n",
        "            'BadRate': bad_rate,\n",
        "            'lift': lift,\n",
        "            'ci_lower': ci_lower,\n",
        "            'ci_upper': ci_upper,\n",
        "            'p_value': p_value,\n",
        "            'significant': p_value < 0.05\n",
        "        })\n",
        "    \n",
        "    result_df = pd.DataFrame(results)\n",
        "    result_df = result_df.sort_values('GoodQualityRate', ascending=False)\n",
        "    return result_df\n",
        "\n",
        "dimensions_to_analyze = []\n",
        "\n",
        "if 'dc_pages' in df.columns:\n",
        "    dimensions_to_analyze.append('dc_pages')\n",
        "if 'design' in df.columns:\n",
        "    dimensions_to_analyze.append('design')\n",
        "if 'bg_color' in df.columns:\n",
        "    dimensions_to_analyze.append('bg_color')\n",
        "if 'publisher_zone' in df.columns:\n",
        "    dimensions_to_analyze.append('publisher_zone')\n",
        "if 'is_call_center' in df.columns:\n",
        "    dimensions_to_analyze.append('is_call_center')\n",
        "if 'address_score_bin' in df.columns:\n",
        "    dimensions_to_analyze.append('address_score_bin')\n",
        "if 'phone_score_bin' in df.columns:\n",
        "    dimensions_to_analyze.append('phone_score_bin')\n",
        "if 'is_branded' in df.columns:\n",
        "    dimensions_to_analyze.append('is_branded')\n",
        "if 'debt_bin' in df.columns:\n",
        "    dimensions_to_analyze.append('debt_bin')\n",
        "if 'state' in df.columns:\n",
        "    dimensions_to_analyze.append('state')\n",
        "if 'traffic_type' in df.columns:\n",
        "    dimensions_to_analyze.append('traffic_type')\n",
        "\n",
        "print(\"Dimensions to analyze:\")\n",
        "print(dimensions_to_analyze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "segment_results = {}\n",
        "\n",
        "for dim in dimensions_to_analyze:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Dimension: {dim}\")\n",
        "    print('='*60)\n",
        "    result = segment_analysis(df, dim, baseline_rate)\n",
        "    segment_results[dim] = result\n",
        "    print(result.to_string())\n",
        "    \n",
        "    print(f\"\\nTop 3 High-Quality Segments:\")\n",
        "    top3 = result.head(3)\n",
        "    for idx, row in top3.iterrows():\n",
        "        sig_mark = \"***\" if row['significant'] else \"\"\n",
        "        print(f\"  {row['segment']}: {row['GoodQualityRate']:.4f} ({row['GoodQualityRate']*100:.2f}%) \"\n",
        "              f\"lift={row['lift']:.2f}x, n={row['leads']} {sig_mark}\")\n",
        "    \n",
        "    print(f\"\\nTop 3 Low-Quality Segments:\")\n",
        "    bottom3 = result.tail(3)\n",
        "    for idx, row in bottom3.iterrows():\n",
        "        sig_mark = \"***\" if row['significant'] else \"\"\n",
        "        print(f\"  {row['segment']}: {row['GoodQualityRate']:.4f} ({row['GoodQualityRate']*100:.2f}%) \"\n",
        "              f\"lift={row['lift']:.2f}x, n={row['leads']} {sig_mark}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Multivariate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "feature_cols = []\n",
        "for col in ['dc_pages', 'design', 'bg_color', 'publisher_zone', 'is_call_center',\n",
        "            'address_score_bin', 'phone_score_bin', 'is_branded', 'debt_bin', \n",
        "            'state', 'traffic_type', 'ad_size']:\n",
        "    if col in df.columns:\n",
        "        feature_cols.append(col)\n",
        "\n",
        "print(f\"Features used: {feature_cols}\")\n",
        "\n",
        "df_model = df[feature_cols + ['is_good']].copy()\n",
        "\n",
        "for col in feature_cols:\n",
        "    df_model[col] = df_model[col].fillna('missing')\n",
        "\n",
        "df_encoded = pd.get_dummies(df_model[feature_cols], prefix=feature_cols)\n",
        "\n",
        "X = df_encoded.values\n",
        "y = df_model['is_good'].values\n",
        "\n",
        "print(f\"\\nFeature dimensions: {X.shape}\")\n",
        "print(f\"Target distribution: {y.sum()} / {len(y)} ({y.mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.api import Logit, add_constant\n",
        "\n",
        "X_with_const = add_constant(X)\n",
        "logit_model = Logit(y, X_with_const)\n",
        "logit_result = logit_model.fit(disp=0, maxiter=1000)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Logistic Regression Model Results\")\n",
        "print(\"=\" * 60)\n",
        "print(logit_result.summary())\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': df_encoded.columns,\n",
        "    'coef': logit_result.params[1:].values,\n",
        "    'p_value': logit_result.pvalues[1:].values\n",
        "})\n",
        "feature_importance['abs_coef'] = np.abs(feature_importance['coef'])\n",
        "feature_importance = feature_importance.sort_values('abs_coef', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features (by absolute coefficient):\")\n",
        "print(feature_importance.head(10).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Random Forest Model Results\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"AUC: {auc:.4f}\")\n",
        "print(f\"PR-AUC: {pr_auc:.4f}\")\n",
        "\n",
        "rf_importance = pd.DataFrame({\n",
        "    'feature': df_encoded.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "})\n",
        "rf_importance = rf_importance.sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Important Features (Random Forest):\")\n",
        "print(rf_importance.head(10).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.3 Driver Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_high_quality = []\n",
        "all_low_quality = []\n",
        "\n",
        "for dim, result_df in segment_results.items():\n",
        "    top3 = result_df.head(3)\n",
        "    bottom3 = result_df.tail(3)\n",
        "    \n",
        "    for idx, row in top3.iterrows():\n",
        "        if row['leads'] >= 50:\n",
        "            all_high_quality.append({\n",
        "                'dimension': dim,\n",
        "                'segment': row['segment'],\n",
        "                'rate': row['GoodQualityRate'],\n",
        "                'lift': row['lift'],\n",
        "                'leads': row['leads']\n",
        "            })\n",
        "    \n",
        "    for idx, row in bottom3.iterrows():\n",
        "        if row['leads'] >= 50:\n",
        "            all_low_quality.append({\n",
        "                'dimension': dim,\n",
        "                'segment': row['segment'],\n",
        "                'rate': row['GoodQualityRate'],\n",
        "                'lift': row['lift'],\n",
        "                'leads': row['leads']\n",
        "            })\n",
        "\n",
        "high_df = pd.DataFrame(all_high_quality).sort_values('rate', ascending=False)\n",
        "low_df = pd.DataFrame(all_low_quality).sort_values('rate', ascending=True)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Driver Summary\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nTop 5 High-Quality Segments (Recommend to Scale):\")\n",
        "print(high_df.head(5).to_string())\n",
        "\n",
        "print(\"\\nTop 5 Low-Quality Segments (Recommend to Cut):\")\n",
        "print(low_df.head(5).to_string())\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
